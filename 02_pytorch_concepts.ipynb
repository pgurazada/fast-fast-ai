{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More PyTorch concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppt.utils import attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "`Dataset` gives you information about the number of samples (implement `__len__`) and gives you the sample at a given index (implement `__getitem__`.\n",
    "It's a nice and simple abstraction to work with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppt.utils import DogsCatsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -d ../data/raw/dogscats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the __len__ method\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the __getitem__ method\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[14][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, datasets offer some convenience functions and attributes.\n",
    "This is not enforced by the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label_id in train_ds:\n",
    "    print(label_id, train_ds.classes[label_id])\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "Common image transformation that can be composed/chained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "IMG_SIZE = 224\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ColorJitter(.3, .3, .3),\n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.Normalize(_mean, _std),\n",
    "])\n",
    "\n",
    "trans(train_ds[13][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref:\n",
    "- https://pytorch.org/docs/stable/torchvision/transforms.htm\n",
    "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "- https://github.com/mdbloice/Augmentor\n",
    "- https://github.com/aleju/imgaug\n",
    "\n",
    "Shout-out:\n",
    "- Hig performance image augmentation with pillow-simd: https://github.com/uploadcare/pillow-simd and http://python-pillow.org/pillow-perf/\n",
    "- [Improving Deep Learning Performance with AutoAugment](https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html) ([paper](https://arxiv.org/abs/1805.09501) | [pytorch implementation](https://github.com/DeepVoltaire/AutoAugment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "The `DataLoader` class offers batch loading of datasets with multi-processing and different sample strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "train_iter = iter(train_dl)\n",
    "X, y = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", transform=trans)\n",
    "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dl)\n",
    "X, y = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler\n",
    "`Sampler` define **how** to sample from the dataset.\n",
    "\n",
    "Examples:\n",
    "- `SequentialSampler`\n",
    "- `RandomSamples`\n",
    "- `SubsetSampler`\n",
    "- `WeightedRandomSampler`\n",
    "\n",
    "Write your own by simply implementing `__iter__` to iterate over the indices of the dataset.\n",
    "\n",
    "Ref:\n",
    "- https://pytorch.org/docs/stable/data.html#torch.utils.data.sampler.Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils.data.sampler.SubsetRandomSampler??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "- Transforms\n",
    "- Dataset\n",
    "- DataLoader\n",
    "- Sampler\n",
    "\n",
    "**simple but extensible interfaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: write your own dataset\n",
    "Extend the `DogsCatsDataset` such that you can specify the size of dataset, i.e. the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
