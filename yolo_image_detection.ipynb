{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo-image-detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1QnNUg-spcTCa9t_qTNtbM_3NPjbSGX2H",
      "authorship_tag": "ABX9TyM6nZff6JukUElMyRDJ4dmI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgurazada/fast-fast-ai/blob/master/yolo_image_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5HNQF2hr4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/cfotache/pytorch_objectdetecttrack.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNZBCgKNCRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash /content/pytorch_objectdetecttrack/config/download_weights.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhUVWOq_Rq4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5l-NSQtRsAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"objectdetector\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Pkg4mONVAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import *\n",
        "from models import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI94XePfRZYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys \n",
        "import time\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnvQs3uR928",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBHrS6LxR_si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQYURjeUSB1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_path='config/yolov3.cfg'\n",
        "weights_path='config/yolov3.weights'\n",
        "class_path='config/coco.names'\n",
        "\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_VbfA7HSF5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Darknet(config_path, img_size=img_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzBh6uaUSIBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(weights_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpi9N6MiSKEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXsTB-rESLvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2czTzeZHSNqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils \n",
        "\n",
        "classes = utils.utils.load_classes(class_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n00L3awSw6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tensor = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwv8QL3qS66l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
        "                        (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
        "    return detections[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cmRxRruS9Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load image and get detections\n",
        "img_path = \"/content/objectdetector/images/chaayos-3-cropped-1571035673.jpg\"\n",
        "prev_time = time.time()\n",
        "img = Image.open(img_path)\n",
        "detections = detect_image(img)\n",
        "inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n",
        "print ('Inference Time: %s' % (inference_time))\n",
        "\n",
        "# Get bounding-box colors\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "img = np.array(img)\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(1, figsize=(12,9))\n",
        "ax.imshow(img)\n",
        "\n",
        "pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "unpad_h = img_size - pad_y\n",
        "unpad_w = img_size - pad_x\n",
        "\n",
        "if detections is not None:\n",
        "    unique_labels = detections[:, -1].cpu().unique()\n",
        "    n_cls_preds = len(unique_labels)\n",
        "    bbox_colors = random.sample(colors, n_cls_preds)\n",
        "    # browse detections and draw bounding boxes\n",
        "    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
        "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
        "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
        "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
        "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
        "        color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
        "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "        plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top',\n",
        "                bbox={'color': color, 'pad': 0})\n",
        "plt.axis('off')\n",
        "# save image\n",
        "plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"), bbox_inches='tight', pad_inches=0.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8EJVtbyTGuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
        "  print(classes[int(cls_pred)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvFrnjA_Xiru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}